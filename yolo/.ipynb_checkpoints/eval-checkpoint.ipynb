{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tawMKjzsHiXS"
   },
   "source": [
    "**Evaluate the YOLO model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31740,
     "status": "ok",
     "timestamp": 1607663279101,
     "user": {
      "displayName": "Haoming Liu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOzSFkObCl-UMX25oW5lPfwwbD5InBzHMI_DJfSw=s64",
      "userId": "10852634671235052019"
     },
     "user_tz": -480
    },
    "id": "gEno-K3tF7pm",
    "outputId": "8da238d3-1fb2-4894-a282-06d72ef66425"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'annotation_preprocess.ipynb', 'data', 'eval.ipynb', 'loss_data', 'map', 'nets', 'predict.ipynb', 'test_img', 'train.ipynb', 'utils', 'yolo.py', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# The working path of this code file should be inside the yolo folder\n",
    "from os import chdir, listdir\n",
    "print(listdir('./'))\n",
    "\n",
    "# chdir('/content/drive/MyDrive/Sem_3/ML/F20_ML_final_project/yolo/')\n",
    "# print(listdir('./'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Ryr5ShXeoN25"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import colorsys\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from yolo import YOLO\n",
    "from nets.yolo4 import YoloBody\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from utils.utils import non_max_suppression, bbox_iou, DecodeBox,letterbox_image,yolo_correct_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10358,
     "status": "ok",
     "timestamp": 1607663353880,
     "user": {
      "displayName": "Haoming Liu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOzSFkObCl-UMX25oW5lPfwwbD5InBzHMI_DJfSw=s64",
      "userId": "10852634671235052019"
     },
     "user_tz": -480
    },
    "id": "4QaRuly0oN3A",
    "outputId": "f56ba8d8-1d39-46b6-84f5-d72b154a9830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating ground-truth!\n",
      "Finish generating ground-truth!\n"
     ]
    }
   ],
   "source": [
    "# Generate the ground-truth\n",
    "\n",
    "idx_to_label = ('without_mask', 'with_mask', 'mask_weared_incorrect')\n",
    "gc_dir = './map/input/ground-truth/'\n",
    "# gc_dir = './../yolo/map/input/ground-truth/'\n",
    "\n",
    "\n",
    "test_img = []\n",
    "print('Start generating ground-truth!')\n",
    "with open('./data/test_data.txt', 'r') as f:\n",
    "    test_data = f.read().split('\\n')\n",
    "    # print(test_dataset)\n",
    "    for i in range(len(test_data)):\n",
    "        if test_data[i].strip() == '':\n",
    "            break\n",
    "        t = test_data[i].split()\n",
    "        img_path = t[0]\n",
    "        objects = t[1:]\n",
    "        test_img.append(img_path)\n",
    "        with open(gc_dir + ('test_%03d.txt' % i), 'w') as f:\n",
    "            for obj in objects:\n",
    "                face_info = obj.split(',')\n",
    "                f.write('%s %s %s %s %s\\n' % (idx_to_label[int(face_info[-1])], face_info[0], face_info[1], face_info[2], face_info[3]))\n",
    "        # if i % 10 == 9:\n",
    "        #     print('Steps: %3d/%3d' % (i + 1, len(test_data)))\n",
    "print('Finish generating ground-truth!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 181508,
     "status": "ok",
     "timestamp": 1607663540249,
     "user": {
      "displayName": "Haoming Liu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOzSFkObCl-UMX25oW5lPfwwbD5InBzHMI_DJfSw=s64",
      "userId": "10852634671235052019"
     },
     "user_tz": -480
    },
    "id": "eh6SaOQgoN3G",
    "outputId": "a21e73ab-0819-4f12-93cc-0a159828389f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start detecting results!\n",
      "Loading pretrained weights.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/yolov4_test_.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8e3675ba268c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Start detecting results!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m \u001b[0myolo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmAP_Yolo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\ML PROJECT\\yolo\\yolo.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manchors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_anchors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m# Initialize classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\ML PROJECT\\yolo\\yolo.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mmodel_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mpretrained_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[0mpretrained_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpretrained_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mmodel_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/yolov4_test_.pth'"
     ]
    }
   ],
   "source": [
    "# making detection-results\n",
    "class mAP_Yolo(YOLO):\n",
    "    #---------------------------------------------------#\n",
    "    #   检测图片\n",
    "    #---------------------------------------------------#\n",
    "    def detect_image(self, image_id, image):\n",
    "        self.confidence = 0.05\n",
    "        image_shape = np.array(np.shape(image)[0:2])\n",
    "\n",
    "        crop_img = np.array(letterbox_image(image, (self.model_image_size[0], self.model_image_size[1])))\n",
    "        photo = np.array(crop_img, dtype = np.float32)\n",
    "        photo /= 255.0\n",
    "        photo = np.transpose(photo, (2, 0, 1))\n",
    "        photo = photo.astype(np.float32)\n",
    "        images = []\n",
    "        images.append(photo)\n",
    "        images = np.asarray(images)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            images = torch.from_numpy(images)\n",
    "            if self.cuda:\n",
    "                images = images.cuda()\n",
    "            outputs = self.net(images)\n",
    "            \n",
    "        output_list = []\n",
    "        for i in range(3):\n",
    "            output_list.append(self.yolo_decodes[i](outputs[i]))\n",
    "        output = torch.cat(output_list, 1)\n",
    "        batch_detections = non_max_suppression(output, len(self.class_names),\n",
    "                                                conf_thres=self.confidence,\n",
    "                                                nms_thres=0.3)\n",
    "\n",
    "        try:\n",
    "            batch_detections = batch_detections[0].cpu().numpy()\n",
    "        except:\n",
    "            return image\n",
    "            \n",
    "        top_index = batch_detections[:,4]*batch_detections[:,5] > self.confidence\n",
    "        top_conf = batch_detections[top_index,4]*batch_detections[top_index,5]\n",
    "        top_label = np.array(batch_detections[top_index,-1],np.int32)\n",
    "        top_bboxes = np.array(batch_detections[top_index,:4])\n",
    "        top_xmin, top_ymin, top_xmax, top_ymax = np.expand_dims(top_bboxes[:,0],-1),np.expand_dims(top_bboxes[:,1],-1),np.expand_dims(top_bboxes[:,2],-1),np.expand_dims(top_bboxes[:,3],-1)\n",
    "\n",
    "        # 去掉灰条\n",
    "        boxes = yolo_correct_boxes(top_ymin,top_xmin,top_ymax,top_xmax,np.array([self.model_image_size[0],self.model_image_size[1]]),image_shape)\n",
    "\n",
    "        with open('./map/input/detection-results/test_' + image_id + '.txt', 'w') as f:\n",
    "            for i, c in enumerate(top_label):\n",
    "                predicted_class = self.class_names[c]\n",
    "                score = str(top_conf[i])\n",
    "\n",
    "                top, left, bottom, right = boxes[i]\n",
    "                f.write(' '.join((str(predicted_class), str(score), str(left), str(top), str(right), str(bottom))) + '\\n')\n",
    "    \n",
    "\n",
    "print('Start detecting results!')\n",
    "\n",
    "yolo = mAP_Yolo()\n",
    "\n",
    "for i in range(len(test_img)):\n",
    "    img = Image.open(test_img[i])\n",
    "    yolo.detect_image('%03d' % i, img)\n",
    "    print('[done]', i)\n",
    "\n",
    "# for image in images:\n",
    "#     img = Image.open(os.path.join(image_path, image))\n",
    "#     yolo.detect_image(image.split('.')[0], img)\n",
    "#     print('[done] ' + image)\n",
    "print('Finish detecting results!')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "eval.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
