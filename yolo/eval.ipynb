{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tawMKjzsHiXS"
   },
   "source": [
    "**Evaluate the YOLO model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31740,
     "status": "ok",
     "timestamp": 1607663279101,
     "user": {
      "displayName": "Haoming Liu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOzSFkObCl-UMX25oW5lPfwwbD5InBzHMI_DJfSw=s64",
      "userId": "10852634671235052019"
     },
     "user_tz": -480
    },
    "id": "gEno-K3tF7pm",
    "outputId": "8da238d3-1fb2-4894-a282-06d72ef66425"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'annotation_preprocess.ipynb', 'data', 'eval.ipynb', 'loss_data', 'map', 'nets', 'predict.ipynb', 'test_img', 'train.ipynb', 'utils', 'yolo.py', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# The working path of this code file should be inside the yolo folder\n",
    "from os import chdir, listdir\n",
    "print(listdir('./'))\n",
    "\n",
    "# chdir('/content/drive/MyDrive/Sem_3/ML/F20_ML_final_project/yolo/')\n",
    "# print(listdir('./'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ryr5ShXeoN25"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import colorsys\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from yolo import YOLO\n",
    "from nets.yolo4 import YoloBody\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from utils.utils import non_max_suppression, bbox_iou, DecodeBox,letterbox_image,yolo_correct_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10358,
     "status": "ok",
     "timestamp": 1607663353880,
     "user": {
      "displayName": "Haoming Liu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOzSFkObCl-UMX25oW5lPfwwbD5InBzHMI_DJfSw=s64",
      "userId": "10852634671235052019"
     },
     "user_tz": -480
    },
    "id": "4QaRuly0oN3A",
    "outputId": "f56ba8d8-1d39-46b6-84f5-d72b154a9830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating ground-truth!\n",
      "Finish generating ground-truth!\n"
     ]
    }
   ],
   "source": [
    "# Generate the ground-truth\n",
    "\n",
    "idx_to_label = ('without_mask', 'with_mask', 'mask_weared_incorrect')\n",
    "gc_dir = './map/input/ground-truth/'\n",
    "# gc_dir = './../yolo/map/input/ground-truth/'\n",
    "\n",
    "\n",
    "test_img = []\n",
    "print('Start generating ground-truth!')\n",
    "with open('./data/test_data.txt', 'r') as f:\n",
    "    test_data = f.read().split('\\n')\n",
    "    # print(test_dataset)\n",
    "    for i in range(len(test_data)):\n",
    "        if test_data[i].strip() == '':\n",
    "            break\n",
    "        t = test_data[i].split()\n",
    "        img_path = t[0]\n",
    "        objects = t[1:]\n",
    "        test_img.append(img_path)\n",
    "        with open(gc_dir + ('test_%03d.txt' % i), 'w') as f:\n",
    "            for obj in objects:\n",
    "                face_info = obj.split(',')\n",
    "                f.write('%s %s %s %s %s\\n' % (idx_to_label[int(face_info[-1])], face_info[0], face_info[1], face_info[2], face_info[3]))\n",
    "        # if i % 10 == 9:\n",
    "        #     print('Steps: %3d/%3d' % (i + 1, len(test_data)))\n",
    "print('Finish generating ground-truth!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 181508,
     "status": "ok",
     "timestamp": 1607663540249,
     "user": {
      "displayName": "Haoming Liu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOzSFkObCl-UMX25oW5lPfwwbD5InBzHMI_DJfSw=s64",
      "userId": "10852634671235052019"
     },
     "user_tz": -480
    },
    "id": "eh6SaOQgoN3G",
    "outputId": "a21e73ab-0819-4f12-93cc-0a159828389f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start detecting results!\n",
      "Loading pretrained weights.\n",
      "Finish loading!\n",
      "./data/yolov4_test.pth model, anchors, and classes loaded.\n",
      "(12, 4)\n",
      "[done] 0\n",
      "(5, 4)\n",
      "[done] 1\n",
      "(5, 4)\n",
      "[done] 2\n",
      "(1, 4)\n",
      "[done] 3\n",
      "(5, 4)\n",
      "[done] 4\n",
      "(1, 4)\n",
      "[done] 5\n",
      "(2, 4)\n",
      "[done] 6\n",
      "(1, 4)\n",
      "[done] 7\n",
      "(3, 4)\n",
      "[done] 8\n",
      "(3, 4)\n",
      "[done] 9\n",
      "(5, 4)\n",
      "[done] 10\n",
      "(4, 4)\n",
      "[done] 11\n",
      "(8, 4)\n",
      "[done] 12\n",
      "(1, 4)\n",
      "[done] 13\n",
      "(1, 4)\n",
      "[done] 14\n",
      "(1, 4)\n",
      "[done] 15\n",
      "(10, 4)\n",
      "[done] 16\n",
      "(2, 4)\n",
      "[done] 17\n",
      "(7, 4)\n",
      "[done] 18\n",
      "(6, 4)\n",
      "[done] 19\n",
      "(3, 4)\n",
      "[done] 20\n",
      "(10, 4)\n",
      "[done] 21\n",
      "(1, 4)\n",
      "[done] 22\n",
      "(5, 4)\n",
      "[done] 23\n",
      "(1, 4)\n",
      "[done] 24\n",
      "(10, 4)\n",
      "[done] 25\n",
      "(3, 4)\n",
      "[done] 26\n",
      "(1, 4)\n",
      "[done] 27\n",
      "(2, 4)\n",
      "[done] 28\n",
      "(5, 4)\n",
      "[done] 29\n",
      "(1, 4)\n",
      "[done] 30\n",
      "(1, 4)\n",
      "[done] 31\n",
      "(9, 4)\n",
      "[done] 32\n",
      "(1, 4)\n",
      "[done] 33\n",
      "(3, 4)\n",
      "[done] 34\n",
      "(4, 4)\n",
      "[done] 35\n",
      "(1, 4)\n",
      "[done] 36\n",
      "(1, 4)\n",
      "[done] 37\n",
      "(1, 4)\n",
      "[done] 38\n",
      "(2, 4)\n",
      "[done] 39\n",
      "(2, 4)\n",
      "[done] 40\n",
      "(8, 4)\n",
      "[done] 41\n",
      "(2, 4)\n",
      "[done] 42\n",
      "(1, 4)\n",
      "[done] 43\n",
      "(5, 4)\n",
      "[done] 44\n",
      "(11, 4)\n",
      "[done] 45\n",
      "(5, 4)\n",
      "[done] 46\n",
      "(2, 4)\n",
      "[done] 47\n",
      "(5, 4)\n",
      "[done] 48\n",
      "(10, 4)\n",
      "[done] 49\n",
      "(4, 4)\n",
      "[done] 50\n",
      "(4, 4)\n",
      "[done] 51\n",
      "(3, 4)\n",
      "[done] 52\n",
      "(4, 4)\n",
      "[done] 53\n",
      "(2, 4)\n",
      "[done] 54\n",
      "(1, 4)\n",
      "[done] 55\n",
      "(3, 4)\n",
      "[done] 56\n",
      "(1, 4)\n",
      "[done] 57\n",
      "(1, 4)\n",
      "[done] 58\n",
      "(1, 4)\n",
      "[done] 59\n",
      "(1, 4)\n",
      "[done] 60\n",
      "(1, 4)\n",
      "[done] 61\n",
      "(7, 4)\n",
      "[done] 62\n",
      "(2, 4)\n",
      "[done] 63\n",
      "(7, 4)\n",
      "[done] 64\n",
      "(3, 4)\n",
      "[done] 65\n",
      "(5, 4)\n",
      "[done] 66\n",
      "(1, 4)\n",
      "[done] 67\n",
      "(4, 4)\n",
      "[done] 68\n",
      "(1, 4)\n",
      "[done] 69\n",
      "(1, 4)\n",
      "[done] 70\n",
      "(5, 4)\n",
      "[done] 71\n",
      "(4, 4)\n",
      "[done] 72\n",
      "(3, 4)\n",
      "[done] 73\n",
      "(3, 4)\n",
      "[done] 74\n",
      "(9, 4)\n",
      "[done] 75\n",
      "(1, 4)\n",
      "[done] 76\n",
      "(5, 4)\n",
      "[done] 77\n",
      "(2, 4)\n",
      "[done] 78\n",
      "(2, 4)\n",
      "[done] 79\n",
      "(2, 4)\n",
      "[done] 80\n",
      "(1, 4)\n",
      "[done] 81\n",
      "(4, 4)\n",
      "[done] 82\n",
      "(1, 4)\n",
      "[done] 83\n",
      "(3, 4)\n",
      "[done] 84\n",
      "(10, 4)\n",
      "[done] 85\n",
      "(4, 4)\n",
      "[done] 86\n",
      "(2, 4)\n",
      "[done] 87\n",
      "(1, 4)\n",
      "[done] 88\n",
      "(5, 4)\n",
      "[done] 89\n",
      "(5, 4)\n",
      "[done] 90\n",
      "(1, 4)\n",
      "[done] 91\n",
      "(4, 4)\n",
      "[done] 92\n",
      "(8, 4)\n",
      "[done] 93\n",
      "(1, 4)\n",
      "[done] 94\n",
      "(1, 4)\n",
      "[done] 95\n",
      "(5, 4)\n",
      "[done] 96\n",
      "(1, 4)\n",
      "[done] 97\n",
      "(9, 4)\n",
      "[done] 98\n",
      "(1, 4)\n",
      "[done] 99\n",
      "(1, 4)\n",
      "[done] 100\n",
      "(1, 4)\n",
      "[done] 101\n",
      "(1, 4)\n",
      "[done] 102\n",
      "(6, 4)\n",
      "[done] 103\n",
      "(1, 4)\n",
      "[done] 104\n",
      "(3, 4)\n",
      "[done] 105\n",
      "(3, 4)\n",
      "[done] 106\n",
      "(1, 4)\n",
      "[done] 107\n",
      "(1, 4)\n",
      "[done] 108\n",
      "(2, 4)\n",
      "[done] 109\n",
      "(1, 4)\n",
      "[done] 110\n",
      "(2, 4)\n",
      "[done] 111\n",
      "(8, 4)\n",
      "[done] 112\n",
      "(4, 4)\n",
      "[done] 113\n",
      "(3, 4)\n",
      "[done] 114\n",
      "(8, 4)\n",
      "[done] 115\n",
      "(1, 4)\n",
      "[done] 116\n",
      "(4, 4)\n",
      "[done] 117\n",
      "(6, 4)\n",
      "[done] 118\n",
      "(6, 4)\n",
      "[done] 119\n",
      "(1, 4)\n",
      "[done] 120\n",
      "(4, 4)\n",
      "[done] 121\n",
      "(1, 4)\n",
      "[done] 122\n",
      "(1, 4)\n",
      "[done] 123\n",
      "(1, 4)\n",
      "[done] 124\n",
      "(7, 4)\n",
      "[done] 125\n",
      "(4, 4)\n",
      "[done] 126\n",
      "(5, 4)\n",
      "[done] 127\n",
      "(1, 4)\n",
      "[done] 128\n",
      "(2, 4)\n",
      "[done] 129\n",
      "(7, 4)\n",
      "[done] 130\n",
      "(5, 4)\n",
      "[done] 131\n",
      "(1, 4)\n",
      "[done] 132\n",
      "(1, 4)\n",
      "[done] 133\n",
      "(1, 4)\n",
      "[done] 134\n",
      "(5, 4)\n",
      "[done] 135\n",
      "(5, 4)\n",
      "[done] 136\n",
      "(4, 4)\n",
      "[done] 137\n",
      "(1, 4)\n",
      "[done] 138\n",
      "(4, 4)\n",
      "[done] 139\n",
      "(5, 4)\n",
      "[done] 140\n",
      "(1, 4)\n",
      "[done] 141\n",
      "(1, 4)\n",
      "[done] 142\n",
      "(1, 4)\n",
      "[done] 143\n",
      "(2, 4)\n",
      "[done] 144\n",
      "(1, 4)\n",
      "[done] 145\n",
      "(1, 4)\n",
      "[done] 146\n",
      "(1, 4)\n",
      "[done] 147\n",
      "(10, 4)\n",
      "[done] 148\n",
      "(11, 4)\n",
      "[done] 149\n",
      "(1, 4)\n",
      "[done] 150\n",
      "(2, 4)\n",
      "[done] 151\n",
      "(3, 4)\n",
      "[done] 152\n",
      "(2, 4)\n",
      "[done] 153\n",
      "(10, 4)\n",
      "[done] 154\n",
      "(1, 4)\n",
      "[done] 155\n",
      "(1, 4)\n",
      "[done] 156\n",
      "Finish detecting results!\n"
     ]
    }
   ],
   "source": [
    "# making detection-results\n",
    "class mAP_Yolo(YOLO):\n",
    "    #---------------------------------------------------#\n",
    "    #   检测图片\n",
    "    #---------------------------------------------------#\n",
    "    def detect_image(self, image_id, image):\n",
    "        self.confidence = 0.05\n",
    "        image_shape = np.array(np.shape(image)[0:2])\n",
    "\n",
    "        crop_img = np.array(letterbox_image(image, (self.model_image_size[0], self.model_image_size[1])))\n",
    "        photo = np.array(crop_img, dtype = np.float32)\n",
    "        photo /= 255.0\n",
    "        photo = np.transpose(photo, (2, 0, 1))\n",
    "        photo = photo.astype(np.float32)\n",
    "        images = []\n",
    "        images.append(photo)\n",
    "        images = np.asarray(images)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            images = torch.from_numpy(images)\n",
    "            if self.cuda:\n",
    "                images = images.cuda()\n",
    "            outputs = self.net(images)\n",
    "            \n",
    "        output_list = []\n",
    "        for i in range(3):\n",
    "            output_list.append(self.yolo_decodes[i](outputs[i]))\n",
    "        output = torch.cat(output_list, 1)\n",
    "        batch_detections = non_max_suppression(output, len(self.class_names),\n",
    "                                                conf_thres=self.confidence,\n",
    "                                                nms_thres=0.3)\n",
    "\n",
    "        try:\n",
    "            batch_detections = batch_detections[0].cpu().numpy()\n",
    "        except:\n",
    "            return image\n",
    "            \n",
    "        top_index = batch_detections[:,4]*batch_detections[:,5] > self.confidence\n",
    "        top_conf = batch_detections[top_index,4]*batch_detections[top_index,5]\n",
    "        top_label = np.array(batch_detections[top_index,-1],np.int32)\n",
    "        top_bboxes = np.array(batch_detections[top_index,:4])\n",
    "        top_xmin, top_ymin, top_xmax, top_ymax = np.expand_dims(top_bboxes[:,0],-1),np.expand_dims(top_bboxes[:,1],-1),np.expand_dims(top_bboxes[:,2],-1),np.expand_dims(top_bboxes[:,3],-1)\n",
    "\n",
    "        # 去掉灰条\n",
    "        boxes = yolo_correct_boxes(top_ymin,top_xmin,top_ymax,top_xmax,np.array([self.model_image_size[0],self.model_image_size[1]]),image_shape)\n",
    "\n",
    "        with open('./map/input/detection-results/test_' + image_id + '.txt', 'w') as f:\n",
    "            for i, c in enumerate(top_label):\n",
    "                predicted_class = self.class_names[c]\n",
    "                score = str(top_conf[i])\n",
    "\n",
    "                top, left, bottom, right = boxes[i]\n",
    "                f.write(' '.join((str(predicted_class), str(score), str(left), str(top), str(right), str(bottom))) + '\\n')\n",
    "    \n",
    "\n",
    "print('Start detecting results!')\n",
    "\n",
    "yolo = mAP_Yolo()\n",
    "\n",
    "for i in range(len(test_img)):\n",
    "    img = Image.open(test_img[i])\n",
    "    yolo.detect_image('%03d' % i, img)\n",
    "    print('[done]', i)\n",
    "\n",
    "# for image in images:\n",
    "#     img = Image.open(os.path.join(image_path, image))\n",
    "#     yolo.detect_image(image.split('.')[0], img)\n",
    "#     print('[done] ' + image)\n",
    "print('Finish detecting results!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "eval.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
